{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d905ca68",
   "metadata": {},
   "source": [
    "# <center>DeepIRTools Tutorial:<br><br>Analyzing a Big-Five Personality Factors Data Set</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917138d1",
   "metadata": {},
   "source": [
    "DeepIRTools is a small Python package that uses scalable deep learning methods (e.g., [Urban and Bauer, 2021](#refs)) to fit several kinds of latent factor models, with a particular focus on item response theory (IRT) models. In this Notebook, we demonstrate some of DeepIRTools' capabilities via a large-scale real data example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b7f8c1",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e417adbd",
   "metadata": {},
   "source": [
    "We begin by downloading and pre-processing the data set, which consists of over 1 million people's responses to 50 Big-Five personality factors items. There are 10 items designed to measure each personality factor (i.e., extraversion, emotional stability, agreeableness, conscientiousness, and openness) and each item has 5 response categories ranging from 1 = Disagree to 5 = Agree.\n",
    "\n",
    "After some basic pre-processing, we cut the data set down to around 621K people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab91f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import deepirtools\n",
    "\n",
    "deepirtools.manual_seed(123) # Set seed for reproducibility.\n",
    "\n",
    "# Download data.\n",
    "filepath = \"./data/IPIP-FFM-data-8Nov2018/data-final.csv\"\n",
    "if not os.path.exists(filepath):\n",
    "    os.makedirs(os.path.dirname(\"./data/\"), exist_ok=True)\n",
    "    urllib.request.urlretrieve(\"https://openpsychometrics.org/_rawdata/IPIP-FFM-data-8Nov2018.zip\",\n",
    "                               \"./data/ipip-ffm.zip\")\n",
    "    shutil.unpack_archive(\"./data/ipip-ffm.zip\", \"./data/\")\n",
    "\n",
    "# Pre-processing.\n",
    "df = pd.read_csv(filepath, sep = \"\\t\", header = 0)\n",
    "df = df[df[\"IPC\"] == 1] # Drop multiple submissions from same IP address.\n",
    "df.iloc[:, :100] = df.iloc[:, :100].dropna() # Drop people with all NaN responses.\n",
    "df = df[df.iloc[:, 0:50].sum(1) > 0] # Drop people with all missing responses.\n",
    "df = df[(df[\"country\"] != \"NONE\") & (~df[\"country\"].isna())] # Drop people for whom no country was recorded.\n",
    "rc_items = [\"EXT2\", \"EXT4\", \"EXT6\", \"EXT8\", \"EXT10\", \"AGR1\", \"AGR3\", \"AGR5\", \"AGR7\",\n",
    "            \"CSN2\", \"CSN4\", \"CSN6\", \"CSN8\", \"EST2\", \"EST4\", \"OPN2\", \"OPN4\", \"OPN6\"]\n",
    "df[rc_items] = ((1 - df[rc_items] / 5) * 5 + 1).mask(lambda col: col == 6, 0) # Reverse-code reverse-coded items.\n",
    "Y = torch.from_numpy(df.iloc[:, :50].to_numpy()) - 1 # Collect item responses.\n",
    "T = torch.from_numpy(df.iloc[:, 50:100].to_numpy()) / 1000 # Collect response times in seconds.\n",
    "\n",
    "country_dummies = pd.get_dummies(df[\"country\"])\n",
    "max_idx = country_dummies.sum(axis=0).argsort()[-1]\n",
    "country_names = [c for c in country_dummies.columns]\n",
    "Z = torch.from_numpy( # Collect covariates.\n",
    "    country_dummies.drop(labels = country_names.pop(max_idx), axis = 1).to_numpy()\n",
    ")\n",
    "\n",
    "missing_mask = 1 * (Y != -1)\n",
    "Y[Y == -1] = 0\n",
    "T[T == 0] = 1e-7 # Set zero response times (which indicate missingness) to a small value.\n",
    "\n",
    "keeps = (((T < 0).sum(dim = 1) == 0) & ((T > 100).sum(dim = 1) == 0) & # Drop negative or overly long response times\n",
    "         (Z.isnan().sum(dim = 1) == 0))                                # and missing baseline covariates.\n",
    "Y, T, missing_mask, Z = Y[keeps], T[keeps], missing_mask[keeps], Z[keeps]\n",
    "\n",
    "print(Y.shape) # Matrix of shape (sample_size, n_items).\n",
    "\n",
    "n_items = Y.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983fc75b",
   "metadata": {},
   "source": [
    "## Exploratory Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1bb6be",
   "metadata": {},
   "source": [
    "We first demonstrate exploratory factor analysis. Since the items are ordinal (ordered categorical), an appropriate measurement model is [Samejima's (1969)](#refs) graded response model (GRM):\n",
    "\\begin{equation}\n",
    "    \\text{Pr}(y_j \\geq k \\mid \\boldsymbol{x}) = \\sigma(\\alpha_{j, k} + \\boldsymbol{\\beta}_j^\\top\\boldsymbol{x}), \\qquad k = 0, 1, \\ldots, K_j - 1,\n",
    "\\end{equation}\n",
    "where $y_j$ is the response to item $j$, $\\boldsymbol{x}$ is a $D \\times 1$ vector of latent variables, $\\alpha_{j, k}$ is the $k^\\text{th}$ category intercept for item $j$, and $\\boldsymbol{\\beta}_j$ is a $D \\times 1$ loadings vector for item $j$, and $K_j$ is the number of responses categories for item $j$, $j = 1, \\ldots, J$. Here, $\\sigma(z) = 1 / (1 + \\exp[-z])$ is the inverse logistic link function. The conditional probability of a particular item response is given by:\n",
    "\\begin{equation}\n",
    "    \\text{Pr}(y_j = k \\mid \\boldsymbol{x}) = \\text{Pr}(y_j \\geq k \\mid \\boldsymbol{x}) - \\text{Pr}(y_j \\geq k + 1 \\mid \\boldsymbol{x}).\n",
    "\\end{equation}\n",
    "\n",
    "A typical goal in the exploratory context is to determine the number of latent factors $D$ underlying the data. We can do this using an approximate log-likelihood (LL) scree plot approach wherein we fit multiple models with different latent dimensions and estimate the approximate LL on a held-out data set for each dimension [(Urban & Bauer, 2021)](#refs). We can then plot these approximate LLs and pick the latent dimension corresponding to an \"elbow\" in the plot.\n",
    "\n",
    "We demonstrate the screeplot approach below. Of particular interest are the `iw_samples_fit` and `iw_samples_ll` arguments. DeepIRTools uses an approximate maximum likelihood (ML) estimator called an importance-weighted amortized variational estimator (I-WAVE) to fit and evaluate models. Increasing the number of importance-weighted (IW) samples during fitting brings our estimates closer to the ML estimates, while doing so during evaluation brings our approximate LL closer to the true LL. However, increasing these arguments may also incur additional computing time. In practice, using a small number of IW samples during fitting often performs well (see [Urban and Bauer, 2021](#refs))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b381b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_sizes = [3, 4, 5, 6, 7, 8] # List of latent dimensions to plot.\n",
    "lrs = [(0.1/(latent_size+1))*5**-1 for latent_size in latent_sizes] # Step sizes for optimization procedure,\n",
    "                                                                    # scaled according to latent dimension.\n",
    "                                                                    # We find this often works well empirically.\n",
    "        \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # Use GPU if available, else use CPU.\n",
    "batch_size = (1024 if device == \"cuda\" else 32) # Use a large optimization batch size if GPU available.\n",
    "\n",
    "# This will take a few minutes to run since we're fitting and evaluating multiple models.\n",
    "ll_list = deepirtools.screeplot(\n",
    "            latent_sizes = latent_sizes,\n",
    "            data = Y,\n",
    "            model_type = \"grm\", # \"grm\" = graded response model.\n",
    "            test_size = 0.01, # Hold out 1 percent of the data for computing the LL.\n",
    "            inference_net_sizes_list = [[100]] * 6, # Neural net sizes.\n",
    "            learning_rates = lrs,\n",
    "            missing_mask = missing_mask, # Indicates locations of missing item responses.\n",
    "            batch_size = batch_size,\n",
    "            device = device,                  \n",
    "            iw_samples_fit = 5, # Increasing improves approximation to the ML estimator during fitting.\n",
    "            iw_samples_ll = 500, # Increasing improves approximation to true LL during evaluation.\n",
    "            n_cats = [5] * n_items, # Number of categories per item.\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace1f4f",
   "metadata": {},
   "source": [
    "Another goal in the exploratory context is to uncover the factor loadings structure. This is typically accomplished by fitting one model with a given latent dimension where the factors are standard normally distributed:\n",
    "\\begin{equation}\n",
    "    \\boldsymbol{x} \\sim \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{I}_D).\n",
    "\\end{equation}\n",
    "The factor loadings are rotated *post-hoc* to arrive at an interpretable solution. If the rotation is oblique, we also obtain estimates of the factor correlations.\n",
    "\n",
    "Since we found an \"elbow\" in our approximate LL scree plot at 5 latent factors, we fit a 5-factor GRM with standard normal factors. We then use Geomin oblique rotation from the FactorAnalyzer package to produce rotated loadings, which have a rather clear simple structure, as well as factor correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepirtools import IWAVE\n",
    "from factor_analyzer import Rotator\n",
    "\n",
    "latent_size = 5\n",
    "lr = (0.1/(latent_size+1))*5**-1\n",
    "\n",
    "model = IWAVE(learning_rate = lr,\n",
    "              model_type = \"grm\",\n",
    "              device = device,\n",
    "              inference_net_sizes = [100],\n",
    "              latent_size = latent_size,\n",
    "              n_cats = [5] * n_items,\n",
    "             )\n",
    "model.fit(Y, batch_size=batch_size, missing_mask=missing_mask, iw_samples=5)\n",
    "\n",
    "rotator = Rotator(method = \"geomin_obl\")\n",
    "rot_loadings = torch.from_numpy(rotator.fit_transform(model.loadings))\n",
    "deepirtools.loadings_heatmap(rot_loadings)\n",
    "print(\"\\nFactor correlations\\n\\n\", np.around(rotator.phi_, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e53493",
   "metadata": {},
   "source": [
    "## Confirmatory Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0562ff0",
   "metadata": {},
   "source": [
    "### Measurement Models for Categorical Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b0569d",
   "metadata": {},
   "source": [
    "In the confirmatory IFA setting, researchers have *a priori* theories that correspond to particular loadings and factor correlation structures. These structures are implemented by placing restrictions on the loadings and factor correlations, and the resulting fitted models are tested for model-data fit.\n",
    "\n",
    "There are several ways to implement loadings constraints. One is to use a $J \\times D$ binary matrix $Q$ whose elements are zero if the corresponding loading is set to zero and one otherwise:\n",
    "\\begin{equation}\n",
    "    \\beta_{j, d} = q_{j, d} \\beta_{j, d}',\n",
    "\\end{equation}\n",
    "where $\\beta_{j, d}$ is the loading for item $j$ on factor $d$, $q_{j, d} \\in \\{0, 1\\}$ is an element of $Q$, and $\\beta_{j, d}'$ is an unconstrained loading.\n",
    "\n",
    "We demonstrate this approach for the GRM by imposing simple stucture on the loadings matrix using $Q$ below. We also estimate the correlations between the latent factors using a spherical parameterization [(Pinheiro & Bates, 1996)](#refs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de964508",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = torch.block_diag(*[torch.ones([10, 1])] * 5) # Binary matrix imposing simple structure on the loadings.\n",
    "\n",
    "model = IWAVE(model_type = \"grm\",\n",
    "              learning_rate = lr,\n",
    "              device = device,\n",
    "              Q = Q,\n",
    "              inference_net_sizes = [100],\n",
    "              latent_size = latent_size,\n",
    "              n_cats = [5] * n_items,\n",
    "              correlated_factors = [0, 1, 2, 3, 4], # Estimates the correlations between any\n",
    "                                                    # factors included in this list; o/s are\n",
    "                                                    # constrained to zero.\n",
    "             )\n",
    "model.fit(Y, batch_size=batch_size, missing_mask=missing_mask, iw_samples=5)\n",
    "\n",
    "print(\"\\nLoadings\\n\\n\", np.around(model.loadings.numpy(), 2))\n",
    "print(\"\\nFactor correlations\\n\\n\", np.around(model.cov.numpy(), 2))\n",
    "print(\"\\nIntercepts\\n\\n\", np.around(model.intercepts.numpy(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c807774",
   "metadata": {},
   "source": [
    "We can implement a wider range of confirmatory IFA models using linear constraints on the loadings:\n",
    "\\begin{equation}\n",
    "    \\boldsymbol{\\beta} = \\boldsymbol{b} + \\boldsymbol{A} \\boldsymbol{\\beta}',\n",
    "\\end{equation}\n",
    "where $\\boldsymbol{\\beta} = (\\beta_{1, 1}, \\ldots, \\beta_{J, 1}, \\ldots, \\beta_{1, D}, \\ldots, \\beta_{J, D})^\\top$ is a $DJ \\times 1$ vector of constrained loadings values, $\\boldsymbol{b}$ is a $DJ \\times 1$ vector of constants, $\\boldsymbol{A}$ is a $DJ \\times DJ$ matrix of constants, and $\\boldsymbol{\\beta}' = (\\beta_{1, 1}', \\ldots, \\beta_{J, 1}', \\ldots, \\beta_{1, D}', \\ldots, \\beta_{J, D}')^\\top$ is a $DJ \\times 1$ vector of unconstrained loadings. This approach is more complicated than using $Q$, but also allows for more complicated constraints like setting a loading to a constant or setting multiple loadings equal.\n",
    "\n",
    "Below, we fit a model with simple structure where the first loading on each factor is constrained to 1 and the factor variances are freely estimated. We also fix one category intercept per factor to zero and freely estimate the factor means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bd39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_ls = ([torch.zeros(1), torch.eye(9), torch.zeros([n_items, n_items]),\n",
    "                  torch.zeros(1), torch.eye(9), torch.zeros([n_items, n_items]),\n",
    "                  torch.zeros(1), torch.eye(9), torch.zeros([n_items, n_items]),\n",
    "                  torch.zeros(1), torch.eye(9), torch.zeros([n_items, n_items]),\n",
    "                  torch.zeros(1), torch.eye(9)])\n",
    "A = torch.block_diag(*constraint_ls)\n",
    "b = torch.cat(([torch.ones(1), torch.zeros([9 + n_items]),\n",
    "                torch.ones(1), torch.zeros([9 + n_items]),\n",
    "                torch.ones(1), torch.zeros([9 + n_items]),\n",
    "                torch.ones(1), torch.zeros([9 + n_items]),\n",
    "                torch.ones(1), torch.zeros([9])]), dim=0)\n",
    "ints_mask = torch.cat([torch.cat([torch.zeros(1), torch.ones(9)], dim=0)] * latent_size, dim=0)\n",
    "\n",
    "model = IWAVE(model_type = \"grm\",\n",
    "              learning_rate = lr,\n",
    "              device = device,\n",
    "              A = A,\n",
    "              b = b,\n",
    "              ints_mask = ints_mask,\n",
    "              inference_net_sizes = [100],\n",
    "              latent_size = latent_size,\n",
    "              n_cats = [5] * n_items,\n",
    "              fixed_variances = False,\n",
    "              fixed_means = False,\n",
    "              correlated_factors = [0, 1, 2, 3, 4],\n",
    "             )\n",
    "model.fit(Y, batch_size=batch_size, missing_mask=missing_mask, iw_samples=5)\n",
    "\n",
    "print(\"\\nLoadings\\n\\n\", np.around(model.loadings.numpy(), 2))\n",
    "print(\"\\nFactor covariances\\n\\n\", np.around(model.cov.numpy(), 2))\n",
    "print(\"\\nIntercepts\\n\\n\", np.around(model.intercepts.numpy(), 2))\n",
    "print(\"\\nFactor means\\n\\n\", np.around(model.mean.numpy(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a42207",
   "metadata": {},
   "source": [
    "As an estimation byproduct, we obtain an artificial neural network (ANN; a kind of nonlinear regression model) that can be used to estimate approximate expected *a posteriori* factor scores or approximate log-likelihoods for data points (even if the data was not used for fitting). To estimate either approximate scores or LLs, two arguments must be specified:\n",
    "1. `mc_samples`, the number of Monte Carlo (MC) samples used.\n",
    "2. `iw_samples`, the number of importance-weighted (IW) samples used.\n",
    "\n",
    "Increasing `mc_samples` reduces sampling variability so that estimates for approximate scores or LLs become more stable across random seeds. Increasing `iw_samples` brings the approximate EAPs and LLs closer to the true EAPs and LLs. However, computation time scales with the product of `mc_samples` and `iw_samples` and may become burdensome when both are too large. The researcher should set these arguments by weighing their computational resources against the needs of the project on hand.\n",
    "\n",
    "We demonstrate approximate factor score and LL estimation for a subset of the Big-Five data below. The negative correlation between emotional stability and most other factors is visible in the scores plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8798bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.scores(Y[:1000], missing_mask[:1000], mc_samples = 1, iw_samples = 500)\n",
    "\n",
    "cols = [\"Externalizing\", \"Emotional Stability\", \"Agreeableness\", \"Conscientiousness\", \"Openness\"]\n",
    "sns.pairplot(pd.DataFrame(scores.numpy(), columns = cols), height = 2)\n",
    "\n",
    "ll = model.log_likelihood(Y[:1000], missing_mask[:1000], mc_samples = 1, iw_samples = 500)\n",
    "print(\"Approximate log-likelihood = \", np.around(ll, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d807e23",
   "metadata": {},
   "source": [
    "**WARNING: The next model is experimental and has not yet been thoroughly evaluated. Use at your own risk.**\n",
    "\n",
    "It is common to assume that the latent factors are normally distributed (i.e., the latent prior is multivariate normal). In general, however, this assumption may be overly restrictive and may lead to poor model-data fit. As an alternative, we can model the latent prior using a flexible density called a neural spline flow [(NSF; Durkan, Bekasov, Murray, & Papamakarios, 2019; Doltabadi, Erfani, & Leckie, 2020)](#refs), which is theoretically capable of approximating any continuous multivariate probability distribution.\n",
    "\n",
    "We demonstrate fitting the GRM with an NSF prior below. Fixied factor variances and means are not currently supported with the NSF prior, so the variances and means are identified by fixing loadings and intercepts as in the previous example. Notice that the factor scores mostly appear nearly normally distributed and the log-likelihood is actually slightly lower than when using a normal density, suggesting that the NSF may provide little benefit for this Big-5 data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e842a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IWAVE(model_type = \"grm\",\n",
    "              learning_rate = 0.001, # Decreased learning rate stabilizes fitting.\n",
    "              device = device,\n",
    "              A = A,\n",
    "              b = b,\n",
    "              ints_mask = ints_mask,\n",
    "              inference_net_sizes = [100],\n",
    "              latent_size = latent_size,\n",
    "              n_cats = [5] * n_items,\n",
    "              fixed_variances = False,\n",
    "              fixed_means = False,\n",
    "              use_spline_prior = True,\n",
    "              count_bins = 8, # Increasing makes density more flexible.\n",
    "              flow_length = 10, # Increasing also makes density more flexible.\n",
    "             )\n",
    "model.fit(Y, , batch_size=64 if device==\"cpu\" else batch_size, missing_mask=missing_mask, iw_samples=5)\n",
    "\n",
    "scores = model.scores(Y[:1000], missing_mask[:1000], mc_samples = 1, iw_samples = 500)\n",
    "\n",
    "cols = [\"Externalizing\", \"Emotional Stability\", \"Agreeableness\", \"Conscientiousness\", \"Openness\"]\n",
    "sns.pairplot(pd.DataFrame(scores.numpy(), columns = cols), height = 2)\n",
    "\n",
    "ll = model.log_likelihood(Y[:1000], missing_mask[:1000], mc_samples = 1, iw_samples = 500)\n",
    "print(\"Approximate log-likelihood = \", np.around(ll, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340e4cea",
   "metadata": {},
   "source": [
    "Besides the GRM, another widely used measurement model for categorical responses is the multidimensional generalized partial credit model (GPCM; [Yao & Schwarz, 2006](#refs)):\n",
    "\\begin{equation}\n",
    "    \\text{Pr}(y_j = k - 1 \\mid \\boldsymbol{x}) = \\frac{\\exp\\big[(k - 1)\\boldsymbol{\\beta}_j^\\top\\boldsymbol{x} - \\sum_{\\ell = 1}^k \\alpha_{j, \\ell} \\big]}{\\sum_{m = 1}^{K_j} \\exp \\big[ (m - 1)\\boldsymbol{\\beta}_j^\\top\\boldsymbol{x} - \\sum_{\\ell = 1}^m \\alpha_{j, \\ell} \\big]}, \\qquad k = 1, \\ldots, K_j,\n",
    "\\end{equation}\n",
    "where all terms are defined as before.\n",
    "\n",
    "We fit this model below using the $Q$ matrix approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa3452c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IWAVE(model_type = \"gpcm\",\n",
    "              learning_rate = lr,\n",
    "              device = device,\n",
    "              Q = Q,\n",
    "              inference_net_sizes = [100],\n",
    "              latent_size = latent_size,\n",
    "              n_cats = [5] * n_items,\n",
    "              correlated_factors = [0, 1, 2, 3, 4],\n",
    "             )\n",
    "model.fit(Y, batch_size=batch_size, missing_mask=missing_mask, iw_samples=5)\n",
    "\n",
    "print(\"\\nLoadings\\n\\n\", np.around(model.loadings.numpy(), 2))\n",
    "print(\"\\nFactor correlations\\n\\n\", np.around(model.cov.numpy(), 2))\n",
    "print(\"\\nIntercepts\\n\\n\", np.around(model.intercepts.numpy(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d58a39",
   "metadata": {},
   "source": [
    "### Measurement Models for Continuous Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21aaa81",
   "metadata": {},
   "source": [
    "We can also fit classical linear factor models of the form:\n",
    "\\begin{equation}\n",
    "    y_j \\mid \\boldsymbol{x} \\sim \\mathcal{N}(\\boldsymbol{\\beta}_j^\\top\\boldsymbol{x} + \\alpha_j, \\sigma_j^2),\n",
    "\\end{equation}\n",
    "where $\\sigma_j^2$ is the residual variance for item $j$, $j = 1, \\ldots, J$.\n",
    "\n",
    "We apply a confirmatory linear factor model to the (standardized) Big-Five data below. This analysis comes with the usual caveat that treating ordinal items as continuous may bias parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48effee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IWAVE(model_type = \"normal\",\n",
    "              learning_rate = lr,\n",
    "              device = device,\n",
    "              Q = Q,\n",
    "              inference_net_sizes = [100],\n",
    "              latent_size = latent_size,\n",
    "              n_items = n_items,\n",
    "              correlated_factors = [0, 1, 2, 3, 4],\n",
    "             )\n",
    "model.fit((Y - Y.mean(dim = 0)) / Y.std(dim = 0), # The data is standardized.\n",
    "          batch_size=batch_size, missing_mask=missing_mask, iw_samples=5)\n",
    "\n",
    "print(\"\\nLoadings\\n\\n\", np.around(model.loadings.numpy(), 2))\n",
    "print(\"\\nFactor correlations\\n\\n\", np.around(model.cov.numpy(), 2))\n",
    "print(\"\\nIntercepts\\n\\n\", np.around(model.intercepts.numpy(), 2))\n",
    "print(\"\\nResidual standard deviations\\n\\n\", np.around(model.residual_std.numpy(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd8747f",
   "metadata": {},
   "source": [
    "It is sometimes of interest to model strictly positive observed variables using a lognormal measurement model:\n",
    "\\begin{equation}\n",
    "    \\ln y_j \\mid \\boldsymbol{x} \\sim \\mathcal{N}(\\boldsymbol{\\beta}_j^\\top\\boldsymbol{x} + \\alpha_j, \\sigma_j^2),\n",
    "\\end{equation}\n",
    "where $y_j > 0$, $j = 1, \\ldots, J$.\n",
    "For intstance, item response times are often modeled as\n",
    "\\begin{equation}\n",
    "    \\ln t_j \\mid \\tau \\sim \\mathcal{N}(\\alpha_j - \\tau, \\sigma_j^2),\n",
    "\\end{equation}\n",
    "where $t_j$ is the time taken to respond to item $j$, $\\tau$ is a scalar latent \"speed\" variable, and all loadings are constrained to $-1$ ([van der Linden, 2006](#refs)). For this model, $\\alpha_j$ is interpreted as the time intensity (i.e., consumingness) of item $j$ and $\\sigma_j^{-1}$ is interpreted as how well item $j$ discriminates between people with different levels of speed.\n",
    "\n",
    "We model the lognormal model to Big-Five response times below. We note that fitting may become numerically unstable when some response times are extremely large. To improve stability (and because extreme response times may be outliers), we have dropped individuals who took more than 100 seconds to respond to any question. If using a CPU, we also decrease the learning rate and increase the batch size, which often helps stabilize fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbfa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.zeros([n_items, n_items])\n",
    "b = -torch.ones(n_items)\n",
    "\n",
    "model = IWAVE(model_type = \"lognormal\",\n",
    "              learning_rate = 0.001,\n",
    "              device = device,\n",
    "              A = A,\n",
    "              b = b,\n",
    "              inference_net_sizes = [100],\n",
    "              latent_size = 1,\n",
    "              n_items = n_items,\n",
    "             )\n",
    "model.fit(T, batch_size=128 if device==\"cpu\" else batch_size, missing_mask=missing_mask, iw_samples=5)\n",
    "\n",
    "print(\"\\nIntensities\\n\\n\", np.around(model.intercepts.numpy(), 2))\n",
    "print(\"\\nDiscriminations\\n\\n\", np.around(model.residual_std.pow(-1).numpy(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7121b68a",
   "metadata": {},
   "source": [
    "### Mixed Categorical and Continuous Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16850b03",
   "metadata": {},
   "source": [
    "It is also possible to model combinations of categorical and continuous items -- in other words, each latent factor can potentially be associated with a combination of item types.\n",
    "\n",
    "As an example, we simultaneously model item responses and response times by choosing a GRM for the item responses and a lognormal model for the response times. In addition to providing estimates for the usual GRM and lognormal model parameters, this approach provides estimates for the correlations between the latent personality factors and the latent speed factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca141fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "constraint_ls = ([torch.eye(10), torch.zeros([int(2 * n_items), int(2 * n_items)]),\n",
    "                  torch.eye(10), torch.zeros([int(2 * n_items), int(2 * n_items)]),\n",
    "                  torch.eye(10), torch.zeros([int(2 * n_items), int(2 * n_items)]),\n",
    "                  torch.eye(10), torch.zeros([int(2 * n_items), int(2 * n_items)]),\n",
    "                  torch.eye(10), torch.zeros([int(3 * n_items), int(3 * n_items)])])\n",
    "A = torch.block_diag(*constraint_ls)\n",
    "b = torch.cat((torch.zeros(int(11 * n_items)), -torch.ones(n_items)), dim = 0)\n",
    "\n",
    "model = IWAVE(model_type = [\"grm\"] * n_items + [\"lognormal\"] * n_items, # We are telling the model that the\n",
    "                                                                        # first 50 observed variables are modeled\n",
    "                                                                        # w/ a GRM and the next 50 are modeled\n",
    "                                                                        # w/ a lognormal model.\n",
    "              learning_rate = lr,\n",
    "              device = device,\n",
    "              A = A,\n",
    "              b = b,\n",
    "              inference_net_sizes = [100],\n",
    "              latent_size = latent_size + 1, # 5 latent personality factors plus 1 latent speed factor.\n",
    "              n_cats = [5] * n_items + [None] * n_items, # We are telling the model that the first 50 items\n",
    "                                                         # have 5 categories and the next 50 are continuous.\n",
    "              correlated_factors = [0, 1, 2, 3, 4, 5], # All factors are correlated.\n",
    "             )\n",
    "\n",
    "combined_data = torch.cat((Y, T), dim = 1) # Combine item responses and response times.\n",
    "combined_missing_mask = torch.cat(2 * [missing_mask], dim = 1) # Missing mask for responses and response times.\n",
    "model.fit(combined_data, batch_size=128 if device==\"cpu\" else batch_size,\n",
    "          missing_mask=combined_missing_mask, iw_samples=5)\n",
    "\n",
    "print(\"\\nFactor correlations\\n\\n\", np.around(model.cov.numpy(), 2))\n",
    "print(\"\\nLoadings\\n\\n\", np.around(model.loadings.numpy(), 2))\n",
    "print(\"\\nIntercepts/intensities\\n\\n\", np.around(model.intercepts.numpy(), 2))\n",
    "print(\"\\nDiscriminations\\n\\n\", np.around(model.residual_std.pow(-1).numpy(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b31d858",
   "metadata": {},
   "source": [
    "### Latent Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e9a2ee",
   "metadata": {},
   "source": [
    "If subject-level covariates are available (e.g., demographic information, baseline measures), we can let the mean of the latent density depend on these covariates as follows:\n",
    "\\begin{equation}\n",
    "    \\boldsymbol{x} \\mid \\boldsymbol{z} \\sim \\mathcal{N}(\\boldsymbol{\\Gamma}^\\top\\boldsymbol{z}, \\boldsymbol{\\Sigma}),\n",
    "\\end{equation}\n",
    "where $\\boldsymbol{\\Gamma}$ is a $D \\times C$ matrix of regression weights, $\\boldsymbol{z}$ is a $C \\times 1$ vector of covariates, and $\\boldsymbol{\\Sigma}$ is a $D \\times D$ factor covariance matrix. Models whose latent densities take this form are sometimes called latent regression models ([Camilli and Fox, 2015](#refs); [von Davier and Sinharay, 2010](#refs)).\n",
    "\n",
    "We fit a latent regression GRM using the country in which the questionnaire was taken as a covariate. There are $C = 219$ countries represented as $C - 1 = 218$ dummy variables with the United States (the country with the highest number of respondents) treated as the reference category (i.e., it has latent mean vector $\\boldsymbol{0}$).\n",
    "\n",
    "Latent regression weights can provide information about between-group differences. For instance, consider the weights for Great Britain, the region with the second highest number of respondents. The weights tell us that respondents from GB had lower mean emotional stability but higher mean extraversion, agreeableness, conscientiousness, and openness compared to respondents from the US. Note that countries with fewer respondents will have relatively more unstable regression weights across random seeds; these weights should be interpreted with caution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a9243c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = IWAVE(model_type = \"grm\",\n",
    "              learning_rate = lr,\n",
    "              device = device,\n",
    "              Q = Q,\n",
    "              inference_net_sizes = [100],\n",
    "              latent_size = latent_size,\n",
    "              n_cats = [5] * n_items,\n",
    "              correlated_factors = [0, 1, 2, 3, 4],\n",
    "              covariate_size = Z.shape[-1],\n",
    "             )\n",
    "model.fit(Y, batch_size=128 if device==\"cpu\" else batch_size,\n",
    "          missing_mask=missing_mask, covariates=Z, iw_samples=5)\n",
    "\n",
    "print(\"\\nLatent regression weights\\n\\n\", np.around(model.latent_regression_weight.numpy(), 3))\n",
    "\n",
    "max2_idx = country_dummies.sum(axis=0).argsort()[-2]\n",
    "print(\"\\nLatent regression weights for\", country_names[max2_idx], \"\\n\\n\",\n",
    "      np.around(model.latent_regression_weight[:, max2_idx].numpy(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5971eba8",
   "metadata": {},
   "source": [
    "## References <a id='refs'></a>\n",
    "\n",
    "- Camilli, G., & Fox, J.-P. (2015). An aggregate IRT procedure for exploratory factor analysis. *Journal of Educational and Behavioral Statistics*, *40*, 377–401.\n",
    "\n",
    "- Dolatabadi, H. M., Erfani, S., & Leckie, C. (2020). Invertible generative modeling using linear rational splines. *Proceedings of the 23<sup>rd</sup> International Conference on Artificial Intelligence and Statistics*, *108*, 4236–4246.\n",
    "\n",
    "- Durkan, C., Bekasov, A., Murray, I., & Papamakarios, G. (2019). Neural spline flows. *Advances in Neural Information Processing Systems*, *32*.\n",
    "\n",
    "- Pinheiro, J. C., & Bates, D. M. (1996). Unconstrained parametrizations for variance-covariance matrices. *Statistics and Computing*, *6*(3), 289–296.\n",
    "\n",
    "- Samejima, F. (1969). Estimation of latent ability using a response pattern of graded scores. *Psychometric Monographs*, *17*.\n",
    "\n",
    "- Urban, C. J., & Bauer, D. J. (2021). A deep learning algorithm for high-dimensional exploratory item factor analysis. *Psychometrika*, *86*(1), 1–29.\n",
    "\n",
    "- van der Linden, W. J. (2006). A lognormal model for response times on test items. *Journal of Educational and Behavioral Statistics*, *31*(2), 181–204.\n",
    "\n",
    "- von Davier, M., & Sinharay, S. (2010). Stochastic approximation methods for latent regression item response models. *Journal of Educational and Behavioral Statistics*, *35*(2), 174–193.\n",
    "\n",
    "- Yao, L., & Schwarz, R. D. (2006). A multidimensional partial credit model with associated item and test statistics: An application to mixed-format tests. *Applied Psychological Measurement*, *30*(6), 469–492."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189e303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
